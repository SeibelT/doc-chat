# DOC-CHAT ğŸ¥ğŸ’¬

Medical information chatbot that explains procedures in plain language.

## Quick Start

### Option 1: Docker (Recommended) ğŸ³

First, install Docker:
- **Windows/Mac**: Go to https://www.docker.com/products/docker-desktop/ and download Docker Desktop
- **Ubuntu/Linux**: Follow the official guide at https://docs.docker.com/engine/install/ubuntu/

After Docker is installed:
```bash
# Run DOC-CHAT
docker compose up
```

That's it! Docker handles everything automatically. Open your browser to the URL shown in the terminal.

### Option 2: Manual Setup

```bash
# 1. Run setup (installs everything automatically)
python setup.py

# 2. Start the app
python app.py
```

## What it does

- Answers medical questions about procedures 
- Adjusts language complexity based on user needs
- Runs 100% locally - your data stays private
- Uses RAG to provide accurate information from medical PDFs

## Docker Setup Details

Docker is the easiest way to run DOC-CHAT. It automatically:
- Creates an isolated environment
- Installs Python and all dependencies
- Installs and configures Ollama
- Downloads AI models (~4GB)
- Sets up the vector database
- No manual installation needed!

### Docker Commands

```bash
# Start the app
docker compose up

# Run in background
docker compose up -d

# Stop the app
docker compose down

# View logs
docker compose logs -f

# Update after code changes
docker compose up --build
```

## Manual Setup Details

If not using Docker, the `setup.py` script handles:
- Installing Python packages
- Installing Ollama (AI backend)
- Downloading Mistral model (~4GB)
- Downloading embedding model
- Creating vector database from PDFs

### Managing Ollama (Manual Setup Only)

Use `ollama_manager.py` for easy management:

```bash
# Check if Ollama is running
python ollama_manager.py status

# Start Ollama
python ollama_manager.py start

# Stop Ollama
python ollama_manager.py stop
```

## Project Structure

```
DOC-CHAT/
â”œâ”€â”€ app.py                              # Main Gradio interface
â”œâ”€â”€ ollama_manager.py                   # Ollama management tool
â”œâ”€â”€ setup.py                            # Automated setup
â”œâ”€â”€ requirements.txt                    # Python dependencies
â”œâ”€â”€ Dockerfile                          # Docker configuration
â”œâ”€â”€ docker-compose.yml                  # Docker compose config
â”œâ”€â”€ .dockerignore                       # Docker ignore file
â”œâ”€â”€ README.md                           # This file
â”œâ”€â”€ .gitignore                          # Git ignore file
â”œâ”€â”€ App/
â”‚   â””â”€â”€ rag/
â”‚       â”œâ”€â”€ assets/                     # Additional assets
â”‚       â”œâ”€â”€ faiss_index/                # Vector database
â”‚       â”œâ”€â”€ create_vector_database_from_pdfs.py
â”‚       â”œâ”€â”€ utils.py                    # Utility functions
â”‚       â”œâ”€â”€ ollama_rag_class.py                 # RAG logic
â”‚       â””â”€â”€ __init__.py                 # Python package init
â”œâ”€â”€ data/
â”‚   â””â”€â”€ pdf_1.pdf                       # Medical PDFs
â””â”€â”€ .gitkeep                            # Git placeholder
```

## Privacy

- Everything runs locally
- No data sent to external servers
- Medical information stays on your machine
- Docker provides additional isolation